{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44820b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from time import time\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0747c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path: Path):\n",
    "    # Data transformation need for ResNet18. It applies only basic cropping\n",
    "    # and normalization.\n",
    "    data_transforms = {\n",
    "        \"train\":\n",
    "            transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        \"val\":\n",
    "            transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    }\n",
    "\n",
    "    # Creates dataset based on a given path.\n",
    "    image_datasets = {\n",
    "        mode: ImageFolder(path / mode, data_transforms[mode])\n",
    "        for mode in [\"train\", \"val\"]\n",
    "    }\n",
    "    #Creates dataloaders from ImageFolders.\n",
    "    dataloaders = {\n",
    "        mode: DataLoader(image_datasets[mode],\n",
    "                         batch_size=4,\n",
    "                         shuffle=True,\n",
    "                         num_workers=4) for mode in [\"train\", \"val\"]\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        mode: len(image_datasets[mode]) for mode in [\"train\", \"val\"]\n",
    "    }\n",
    "    class_names = image_datasets[\"train\"].classes\n",
    "    return dataloaders, dataset_sizes, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4dadf41-f6d3-4d53-930e-86775e75f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloaders,\n",
    "                model,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                num_epochs=15,\n",
    "                device=\"cpu\"):\n",
    "    start = time()\n",
    "\n",
    "    # Need to keep best model.\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Repeat traning num_epochs time.\n",
    "    for epoch in range(num_epochs):\n",
    "        print(20 * \"-\")\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "\n",
    "        # Each iteration consists of a training phase and a validation phase.\n",
    "        for mode in [\"train\", \"val\"]:\n",
    "            if mode == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[mode]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(mode == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Perform backpropagation only in training mode.\n",
    "                    if mode == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if mode == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate loss and accuracy.\n",
    "            epoch_loss = running_loss / dataset_sizes[mode]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[mode]\n",
    "\n",
    "            print(f\"{mode} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Save model if it is the best so far.\n",
    "            if mode == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    end = time()\n",
    "    time_elapsed = end - start\n",
    "    print(\n",
    "        f\"Training complete in {time_elapsed // 60:.0f}min {time_elapsed % 60:.0f}s\"\n",
    "    )\n",
    "    print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d3f6aa9-2897-4202-b1f0-9c27488c9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(device=\"cpu\"):\n",
    "    # Download pretrained model.\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Freeze ResNet18 disabling requires_grad.\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Newly constructed module has requires_grad=True by default.\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 3)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4ae1bec-6a28-4b84-8304-ae9b1734ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders, dataset_sizes, class_names = prepare_data(\n",
    "    Path(\"../data/sharks_subset_tests\"))\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Only parameters of final layer are being optimized.\n",
    "optimizer = SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d080386-02ba-4e57-89b6-657b4627d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Epoch 0/14\n",
      "train Loss: 1.0175 Acc: 0.5049\n",
      "val Loss: 1.4237 Acc: 0.4273\n",
      "\n",
      "--------------------\n",
      "Epoch 1/14\n",
      "train Loss: 0.8084 Acc: 0.6324\n",
      "val Loss: 0.5947 Acc: 0.7091\n",
      "\n",
      "--------------------\n",
      "Epoch 2/14\n",
      "train Loss: 0.6662 Acc: 0.6814\n",
      "val Loss: 0.4379 Acc: 0.7818\n",
      "\n",
      "--------------------\n",
      "Epoch 3/14\n",
      "train Loss: 0.6164 Acc: 0.7598\n",
      "val Loss: 0.3931 Acc: 0.8364\n",
      "\n",
      "--------------------\n",
      "Epoch 4/14\n",
      "train Loss: 0.7434 Acc: 0.6912\n",
      "val Loss: 0.4757 Acc: 0.8364\n",
      "\n",
      "--------------------\n",
      "Epoch 5/14\n",
      "train Loss: 0.6746 Acc: 0.7206\n",
      "val Loss: 0.3098 Acc: 0.8545\n",
      "\n",
      "--------------------\n",
      "Epoch 6/14\n",
      "train Loss: 0.7386 Acc: 0.6961\n",
      "val Loss: 0.5183 Acc: 0.8000\n",
      "\n",
      "--------------------\n",
      "Epoch 7/14\n",
      "train Loss: 0.5781 Acc: 0.7010\n",
      "val Loss: 0.3572 Acc: 0.8455\n",
      "\n",
      "--------------------\n",
      "Epoch 8/14\n",
      "train Loss: 0.4691 Acc: 0.8039\n",
      "val Loss: 0.3995 Acc: 0.8364\n",
      "\n",
      "--------------------\n",
      "Epoch 9/14\n",
      "train Loss: 0.4770 Acc: 0.8186\n",
      "val Loss: 0.3941 Acc: 0.8273\n",
      "\n",
      "--------------------\n",
      "Epoch 10/14\n",
      "train Loss: 0.5285 Acc: 0.7941\n",
      "val Loss: 0.3511 Acc: 0.8364\n",
      "\n",
      "--------------------\n",
      "Epoch 11/14\n",
      "train Loss: 0.3545 Acc: 0.8333\n",
      "val Loss: 0.3451 Acc: 0.8545\n",
      "\n",
      "--------------------\n",
      "Epoch 12/14\n",
      "train Loss: 0.5247 Acc: 0.7745\n",
      "val Loss: 0.3734 Acc: 0.8545\n",
      "\n",
      "--------------------\n",
      "Epoch 13/14\n",
      "train Loss: 0.4597 Acc: 0.7843\n",
      "val Loss: 0.3760 Acc: 0.8364\n",
      "\n",
      "--------------------\n",
      "Epoch 14/14\n",
      "train Loss: 0.5454 Acc: 0.8039\n",
      "val Loss: 0.3157 Acc: 0.8636\n",
      "\n",
      "Training complete in 9min 22s\n",
      "Best val Acc: 0.863636\n"
     ]
    }
   ],
   "source": [
    "train_model(dataloaders, model, criterion, optimizer, scheduler);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c776f96-2276-4e69-bee6-9dd7b105e270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
